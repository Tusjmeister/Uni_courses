# -*- coding: utf-8 -*-
"""CA1_group9.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pP8xiMJyHpkDwRchE36pBWK0gwmEmzmI

# DAT300 - Compulsory assignment 1

## Group 9
Group name: Goofy  
  
## Members
- Joel Teklemariam
- Artush Mkrtchyan

# Introduction

From what we have understood, the task is to make an ensemble model, a classification model and an ANN to predict forest types in different national parks. We are then going to compare the results and conclude which one was the best. 

Our roles are exactly the same, because most of the time we have been sitting together to complete this assignment. That means both of us have coded and written text like this one.

# Data pre-processing and visualisation
"""

from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold
from sklearn.metrics import f1_score, confusion_matrix, roc_curve, auc
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.pipeline import make_pipeline
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.decomposition import PCA
from scipy import stats
from tensorflow.keras import models, layers
from tensorflow.keras.optimizers import Adam, Adamax, Adadelta
from tensorflow.keras.layers import LeakyReLU, PReLU, Dropout
from tensorflow.keras.callbacks import EarlyStopping

import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
import numpy as np

"""As seen above, we're importing what we think we may need for this project"""

raw_data = pd.read_csv('/content/train.csv', index_col=0, delimiter=';') # Naming the train data "raw_data"
test_data = pd.read_csv('/content/test.csv', index_col=0, delimiter=';') # Naming the test data "test_data"

print(raw_data.isnull().sum()) # Checking how many NaN there are
raw_data.head()
raw_data.info()

print(test_data.isnull().sum()) # Checking how many NaN there are
test_data.head()
test_data.info()

"""What we found out is that this dataset does not contain any NaN values"""

# Histograms below

raw_data.hist(figsize=(25, 25))
plt.tight_layout()
plt.show()

"""We can see that there are no instances of soil type 7 and 15.
Furthermore, one can see that most of the data is skewed, which can affect the results later.
"""

# Removing the columns soil 7 and soil 15

raw_data.drop(columns=["Soil 7", "Soil 15"], inplace=True)
test_data.drop(columns=["Soil 7", "Soil 15"], inplace=True)

raw_data.iloc[:,0:11].head()
le = LabelEncoder() 

dummies = pd.get_dummies(raw_data["National Park"], drop_first=True)
raw_data["Forest type"] = le.fit_transform(raw_data["Forest type"])

enc_data = pd.concat([raw_data, dummies], axis=1)
enc_data = enc_data._get_numeric_data()

enc_data.head()

test_data.iloc[:,0:11].head()
le = LabelEncoder()

dummies_test = pd.get_dummies(test_data["National Park"], drop_first=True)
enc_test = pd.concat([test_data, dummies_test], axis=1) # Merging / concatenating two dataframes
enc_test = enc_test._get_numeric_data()
test_data.head()

"""We are making dummies out of the categorical column "National Park" and later concatenating the dummies with the original dataframe."""

plt.figure(figsize=(15, 15)) # Making it big for easier inspection
sliced_data = enc_data.iloc[:,0:11]
corr_matrix1 = sliced_data.corr()

sns.heatmap(corr_matrix1, annot=True)
plt.show()

plt.figure(figsize=(15, 15)) # Making it big for easier inspection
sliced_data = enc_data.iloc[:,10:50]
corr_matrix1 = sliced_data.corr()

sns.heatmap(corr_matrix1, annot=True)
plt.show()


# there is almost no correlation between the soils.

"""As mentioned under the histograms, there are no instances of soil 7 and soil 15. This is further visualised in the heatmap shown above.
Furthermore, one can see from the heatmap that the soils have little to no correleation between them.

# Modelling

## 1. Scikit-learn

To be honest, we had more problems with our SCI-kit models than with our ANN model. That is because we tried to do a grid search on Gradient Boosting Classifier and SVC. Since the dataset is enormous, the process of training the models took several hours. That is why we removed grid search altogether and even changed which models we use. Therefore, we use Logistic Regression instead of SVC and Random Forest instead of Gradient Boosting Classifier. 

Furthermore, we did not test the Random Forest on all the data as a whole, because the model did not stop running even after three hours. Additionally, 
we just want to mention that all the models did relatively well on the same problem in terms of accuracy. Only difference is that our ANN model was on average faster than our shallow learning models when we tried to tune them. Without tuning, our shallow learning models were faster than our ANN model.

### Classification model based on algorithms from scikit-learn (e.g. logistic regression, possibly regularized, Support Vector Classifier, etc.).
"""

# Code for scikit-learn based model

X = enc_data.drop(["Forest type"], axis=1)
y = enc_data["Forest type"]

X_train, X_test, y_train, y_test = train_test_split(
    X,y, test_size=0.3, random_state=21)

print("X_train: ",X_train.shape)
print("X_test: ",X_test.shape)
print("y_train: ",y_train.shape)
print("y_test: ",y_test.shape)

"""Scaling the data below for use in logistic regression"""

# Scaling the data with StandardScaler()

sc = StandardScaler()
sc.fit(X_train)


# Transform (standardise) both X_train and X_test with mean and STD from 
# training data

X_train_sc = sc.transform(X_train)
X_test_sc = sc.transform(X_test)

lr = make_pipeline(
    StandardScaler(),
    LogisticRegression(random_state=21,
                       n_jobs=-1),).fit(X_train_sc, y_train)
    
lr.predict(X_test_sc)



print('Logistic Regression training data accuracy: {0:.4f}'.format(
    lr.score(X_train_sc, y_train)))

print('Logistic Regression test data accuracy: {0:.4f}'.format(
    lr.score(X_test_sc, y_test)))

"""### Ensemble model (e.g. random forest or similar)

Ensemble model of Random Forest Classifier
"""

rand = RandomForestClassifier(random_state=21,
                                 n_estimators= 100,
                                 max_features= "auto"
                                 )

rand.fit(X_train, y_train) # training the random forest
# Should have trained with the whole data X and y but it took too much time

print('Random forest training data accuracy: {0:.4f}'.format(
    rand.score(X_train, y_train)))

print('Random forest test data accuracy: {0:.4f}'.format(
    rand.score(X_test, y_test)))

"""## 2. Neural Network with Keras

When we started we made the mistake of not using the sigmoid activation function nor the binary crossentropy loss function. Because of this, our results started out quite bad, but after realizing this we quickly fixed it.
We have also tried several different activation functions like PreLU and Swish, but quickly settled with ELU. In terms of optimizers, we found out that the standard Adam works best. Much better than Adagrad and Adadelta, but only slightly better than rmsprop. We also started with few neurons, but quickly found out that using big handfuls of neurons was the best option.

We used many attempts to get above the beat me since we could not get past 96% for the first few days. After a while we managed that by using ELU starting with 1024 neurons and halving the number for each layer. All in all, this task required a lot of trial and error in terms of tuning the ANN model.

"""

# Code for creating and training a ANN with Keras

model = models.Sequential([
    layers.Dense(1024, activation ="ELU"),
    layers.Dense(512, activation = "ELU"),
    layers.Dense(256, activation = "ELU"),
    layers.Dense(128, activation = "ELU"),
    layers.Dense(64, activation = "ELU"),
    layers.Dense(1, activation = "sigmoid")])

# Compile model
model.compile(optimizer=Adam(learning_rate=0.0005),
              loss='binary_crossentropy',
              metrics=['accuracy'])

callback = EarlyStopping(monitor='loss', patience=5)

# Fit model (in the same manner as you would with scikit-learn)
model.fit(X_train, 
          y_train,
          epochs=100,
          callbacks= callback,
          batch_size=160,
          validation_split=0.4)

model.summary()

predictions = model.predict(enc_test)

model.evaluate(X_test, y_test)

"""### ANN Results

Report on your best ANN found and print out relevant metrics
"""

submission_df = pd.DataFrame(data=list(range(len(predictions))), 
                             columns=["Index"])

submission_df["Predicted"] = predictions
submission_df = submission_df.round(0)
                                    
submission_df['Predicted'] = np.where(submission_df['Predicted'] == 1,
                                      "Lodgepole", "Cottonwood")

submission_df.to_csv("CA1_goofy_submission4.csv", index=False)
submission_df

"""# Discussion / conclusion

Provide a summary of the assignment: (you are required to address **the first three** points of the list below)
- obstacles / problems you have met regarding the modelling proces
- degree of success of the three models
- given more time, what would be done differently
- further comments (if any)

We had problems running the ensemble classifier, especially when using the support vector classifier. The main problem was the amount of time it took to run the code for the whole training data. Later we decided to use a logistic regressor to classify. We also had to preprocess the data differently than we initially had planned. We first used the LabelEncoder for categorical data in column National Park, but then changed it to dummies. Given more time, we would experiment with other activation and loss functions. We had some ideas to make the model more complex without overfitting it, as in adding more layers and implement more neurons to the layers. 

To conclude, our models were all quite accurate on predicting with an average of about 97%. The only difference were how fast the models were at training, where the shallow learning models did not hold well against our ANN model when doing grid searches.
"""